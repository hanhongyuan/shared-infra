---
# determine the status of each manager node and break them
# into two groups:
#   - swarm_manager_operational (swarm is running and active)
#   - swarm_manager_bootstrap (host needs to be joined to the cluster)
- hosts: tag_jra_environment_{{ env }}:&tag_jra_swarm_instance_type_swarm_manager
  become: true
  tasks:
    - name: determine swarm status
      shell: >
        docker info | egrep '^Swarm: ' | cut -d ' ' -f2
      register: swarm_status

    - name: create swarm_manager_operational group
      add_host:
        hostname: "{{ item }}"
        groups: swarm_manager_operational
      with_items: "{{ ansible_play_hosts | default(play_hosts) }}"
      when: "'active' in hostvars[item].swarm_status.stdout_lines"
      run_once: true

    - name: create swarm_manager_bootstrap group
      add_host:
        hostname: "{{ item }}"
        groups: swarm_manager_bootstrap
      with_items: "{{ ansible_play_hosts | default(play_hosts) }}"
      when: "'active' not in hostvars[item].swarm_status.stdout_lines"
      run_once: true


# Create the traefix proxy overlay network
- hosts: swarm_manager_operational[0]
  become: true
  tasks:
    - name: create proxy traefic overlay network
      shell: >
        docker network create --driver=overlay jarch-proxy-traefik-network
      ignore_errors: yes


# Deploy the Traefik Proxy service
- hosts: swarm_manager_operational[0]
  become: true
  tasks:
    - name: remove jarch-infra-proxy-traefik service if it exists (ignore failure if it does not exist)
      shell: >
        docker service rm jarch-infra-proxy-traefik
      ignore_errors: yes

    - name: deploy traefix service
      shell: >
        docker service create
        --name jarch-infra-proxy-traefik
        --constraint 'node.role == manager'
        --constraint 'node.labels.jra.failure-zone == us-east-1-az-1'
        --label traefik.docker.network=jarch-proxy-traefik-network
        --label traefik.port=8080
        --label traefik.frontend.rule=Host:{{ env_domain_prefix }}proxy.joericearchitect.info
        --label jra.environment-flip=blue
        --label jra.application-name=jarch-infra-proxy-traefik
        --label jra.container-name=jarch-infra-proxy-traefik
        --label jra.domain-name={{ env_domain_prefix }}proxy.joericearchitect.info
        --publish 80:80
        --publish 8188:8080
        --mount type=bind,source=/var/run/docker.sock,target=/var/run/docker.sock
        --network jarch-proxy-traefik-network
        traefik:v1.1.0
        --docker
        --docker.swarmmode
        --docker.domain=traefik
        --docker.watch
        --web

# Make sure the proper volume mount points are created on all the management nodes
#   NOTE:  in the future, management will have its own separate node.  For now, all management services will go on
#          'build' nodes.  In the future, change the host selector to be management nodes, not build nodes.
- hosts: tag_jra_environment_{{ env }}:&tag_jra_swarm_node_type_infra_build
  become: true
  tasks:
    - name: create the docker registry data mount directory if it doesn't already exist
      shell: >
        sudo mkdir -p /usr/local/jra/docker-data-volumes/jra-infra/docker-registry/data
      ignore_errors: yes

    - name: create the docker registry cert mount directory if it doesn't already exist
      shell: >
        sudo mkdir -p /usr/local/jra/docker-data-volumes/jra-infra/docker-registry/certs
      ignore_errors: yes

    - name: make sure the processes running inside containers have access to the data directories
      shell: >
        sudo chmod -R 777 /usr/local/jra/docker-data-volumes
      ignore_errors: yes

# Deploy the Docker Registy service
- hosts: swarm_manager_operational[0]
  become: true
  tasks:
    - name: remove jarch-infra-docker-registry service if it exists (ignore failure if it does not exist)
      shell: >
        docker service rm jarch-infra-docker-registry
      ignore_errors: yes

    - name: deploy docker registry service
      shell: >
        docker service create
        --name jarch-infra-docker-registry
        --publish 8183:5000
        --network jarch-proxy-traefik-network
        --mount type=bind,src=/usr/local/jra/docker-data-volumes/jra-infra/docker-registry/data,dst=/var/lib/registry
        --mount type=bind,src=/usr/local/jra/docker-data-volumes/jra-infra/docker-registry/certs,dst=/certs
        --constraint 'node.labels.jra.swarm-node-type == infra-build'
        --label traefik.docker.network=jarch-proxy-traefik-network
        --label traefik.port=5000
        --label traefik.frontend.rule=Host:{{ env_domain_prefix }}docker.joericearchitect.info
        --label jra.environment-flip=blue
        --label jra.application-name=jarch-infra-docker-registry
        --label jra.container-name="jarch-infra-docker-registry"
        --label jra.domain-name={{ env_domain_prefix }}docker.joericearchitect.info
        registry:2

# Make sure the proper volume mount points are created on all the swarm manager nodes
- hosts: tag_jra_environment_{{ env }}:&tag_jra_swarm_node_type_infra_build
  become: true
  tasks:
    - name: create the jenkins mount directory if it doesn't already exist
      shell: >
        sudo mkdir -p /usr/local/jra/docker-data-volumes/jra-infra/build-jenkins/home
      ignore_errors: yes

    - name: make sure the processes running inside containers have access to the directories
      shell: >
        sudo chmod -R 777 /usr/local/jra/docker-data-volumes
      ignore_errors: yes

# Deploy the Jenkins service
- hosts: swarm_manager_operational[0]
  become: true
  tasks:
    - name: remove the jarch-infra-build-jenkins service if it exists (ignore failure if it does not exist)
      shell: >
        docker service rm jarch-infra-build-jenkins
      ignore_errors: yes

    - name: deploy Jenkins service
      shell: >
        docker service create
        --name jarch-infra-build-jenkins
        --publish 8180:8080
        --replicas=1
        --constraint 'node.labels.jra.swarm-node-type == infra-build'
        --network jarch-proxy-traefik-network
        --mount type=bind,src=/usr/local/jra/docker-data-volumes/jra-infra/build-jenkins/home,dst=/var/jenkins_home \
        --label traefik.docker.network=jarch-proxy-traefik-network
        --label traefik.port=8080
        --label traefik.frontend.rule=Host:{{ env_domain_prefix }}build.joericearchitect.info
        --label jra.environment-flip="blue"
        --label jra.application-name="jarch-infra-build-jenkins"
        --label jra.container-name="jarch-infra-build-jenkins"
        --label jra.domain-name={{ env_domain_prefix }}build.joericearchitect.info
        jenkins

# Make sure the proper volume mount points are created on all the swarm manager nodes
- hosts: tag_jra_environment_{{ env }}:&tag_jra_swarm_instance_type_swarm_manager
  become: true
  tasks:
    - name: create the portainer mount directory if it doesn't already exist
      shell: >
        sudo mkdir -p /usr/local/jra/docker-data-volumes/jra-infra/docker-ui-portainer/data
      ignore_errors: yes

    - name: make sure the processes running inside containers have access to the directories
      shell: >
        sudo chmod -R 777 /usr/local/jra/docker-data-volumes
      ignore_errors: yes

# Deploy the Portainer service
- hosts: swarm_manager_operational[0]
  become: true
  tasks:
    - name: remove the jarch-infra-docker-ui-portainer service if it exists (ignore failure if it does not exist)
      shell: >
        docker service rm jarch-infra-docker-ui-portainer
      ignore_errors: yes

    - name: deploy Portainer service
      shell: >
        docker service create
        --name jarch-infra-docker-ui-portainer
        --publish 8184:9000
        --constraint 'node.role == manager'
        --constraint 'node.labels.jra.failure-zone == us-east-1-az-2'
        --network jarch-proxy-traefik-network
        --mount type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock
        --mount type=bind,src=/usr/local/jra/docker-data-volumes/jra-infra/docker-ui-portainer/data,dst=/data
        --label traefik.docker.network=jarch-proxy-traefik-network
        --label traefik.port=9000
        --label traefik.frontend.rule=Host:{{ env_domain_prefix }}dockerui.joericearchitect.info
        --label jra.environment-flip=blue
        --label jra.application-name=jarch-infra-docker-ui-portainer
        --label jra.container-name=jarch-infra-docker-ui-portainer
        --label jra.domain-name={{ env_domain_prefix }}dockerui.joericearchitect.info
        portainer/portainer
        -H unix:///var/run/docker.sock

# Deploy the docker swarm visualizer service
- hosts: swarm_manager_operational[0]
  become: true
  tasks:
    - name: remove the jarch-infra-docker-ui-docker visualizer service if it exists (ignore failure if it does not exist)
      shell: >
        docker service rm jarch-infra-docker-ui-visualizer
      ignore_errors: yes

    - name: deploy Docker visualizer service
      shell: >
        docker service create
        --name jarch-infra-docker-ui-visualizer
        --publish 8190:8080/tcp
        --constraint 'node.role == manager'
        --constraint 'node.labels.jra.failure-zone == us-east-1-az-3'
        --network jarch-proxy-traefik-network
        --mount type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock
        --label traefik.docker.network=jarch-proxy-traefik-network
        --label traefik.port=8080
        --label traefik.frontend.rule=Host:{{ env_domain_prefix }}dockervisual.joericearchitect.info
        --label jra.environment-flip=blue
        --label jra.application-name=jarch-infra-docker-ui-visualizer
        --label jra.container-name=jarch-infra-docker-ui-visualizer
        --label jra.domain-name={{ env_domain_prefix }}dockervisual.joericearchitect.info
        manomarks/visualizer

# Make sure the elasticsearch volume mount points are created on all the swarm manager nodes
- hosts: tag_jra_environment_{{ env }}:&tag_jra_swarm_instance_type_swarm_manager
  become: true
  tasks:
    - name: create the elasticsearch mount directory if it doesn't already exist
      shell: >
        sudo mkdir -p sudo mkdir -p /usr/local/jra/docker-data-volumes/jra-infra/logging-elasticsearch/data
      ignore_errors: yes

    - name: make sure the processes running inside containers have access to the directories
      shell: >
        sudo chmod -R 777 /usr/local/jra/docker-data-volumes
      ignore_errors: yes

    - name: update the mmap limit because elasticsearch needs it
      shell: >
        sudo sysctl -w vm.max_map_count=262144 &&
        sudo bash -c 'sudo echo "vm.max_map_count=262144" >> /etc/sysctl.conf'
      ignore_errors: yes

# Create the logging overlay network
- hosts: swarm_manager_operational[0]
  become: true
  tasks:
    - name: create logging overlay network
      shell: >
        docker network create --driver=overlay jarch-infra-logging-network
      ignore_errors: yes

