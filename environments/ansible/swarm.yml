---
# determine the status of each manager node and break them
# into two groups:
#   - swarm_manager_operational (swarm is running and active)
#   - swarm_manager_bootstrap (host needs to be joined to the cluster)
- hosts: tag_environment_{{ env }}:&tag_swarm_instance_type_swarm_manager
  become: true
  tasks:
    - name: determine swarm status
      shell: >
        docker info | egrep '^Swarm: ' | cut -d ' ' -f2
      register: swarm_status

    - name: Print manager host name
      debug: msg="manager-host-name='{{ ec2_private_dns_name }}'"

    - name: Print manager node name (with regex)
      debug: msg="manager-host-name='{{ ec2_private_dns_name | regex_replace('(ip-[0-9]*-[0-9]*-[0-9]*-[0-9]*)\.[a-zA-Z0-9]*\.[a-zA-Z0-9]*', '\\1')}}'"

    - name: create swarm_manager_operational group
      add_host:
        hostname: "{{ item }}"
        groups: swarm_manager_operational
      with_items: "{{ ansible_play_hosts | default(play_hosts) }}"
      when: "'active' in hostvars[item].swarm_status.stdout_lines"
      run_once: true

    - name: create swarm_manager_bootstrap group
      add_host:
        hostname: "{{ item }}"
        groups: swarm_manager_bootstrap
      with_items: "{{ ansible_play_hosts | default(play_hosts) }}"
      when: "'active' not in hostvars[item].swarm_status.stdout_lines"
      run_once: true

# determine the status of each worker node and break them
# into two groups:
#   - swarm_worker_operational (host is joined to the swarm cluster)
#   - swarm_worker_bootstrap (host needs to be joined to the cluster)
- hosts: tag_environment_{{ env }}:&tag_swarm_instance_type_swarm_node
  become: true
  tasks:
    - name: determine swarm status
      shell: >
        docker info | egrep '^Swarm: ' | cut -d ' ' -f2
      register: swarm_status

    - name: Print worker host name
      debug: msg="worker-host-name='{{ ec2_private_dns_name }}'"

    - name: Print worker node name
      debug: msg="manager-host-name='{{ ec2_private_dns_name | regex_replace('(ip-[0-9]*-[0-9]*-[0-9]*-[0-9]*)\.[a-zA-Z0-9]*\.[a-zA-Z0-9]*', '\\1')}}'"

    - name: create swarm_worker_operational group
      add_host:
        hostname: "{{ item }}"
        groups: swarm_worker_operational
      with_items: "{{ ansible_play_hosts | default(play_hosts) }}"
      when: "'active' in hostvars[item].swarm_status.stdout_lines"
      run_once: true

    - name: create swarm_worker_bootstrap group
      add_host:
        hostname: "{{ item }}"
        groups: swarm_worker_bootstrap
      with_items: "{{ ansible_play_hosts | default(play_hosts) }}"
      when: "'active' not in hostvars[item].swarm_status.stdout_lines"
      run_once: true

# when the swarm_manager_operational group is empty, meaning there
# are no hosts running swarm, we need to initialize one of the hosts
# then add it to the swarm_manager_operational group
- hosts: swarm_manager_bootstrap[0]
  become: true
  vars:
    swarm_node_host_name: "{{ ec2_private_dns_name | regex_replace('(ip-[0-9]*-[0-9]*-[0-9]*-[0-9]*)\\.[a-zA-Z0-9]*\\.[a-zA-Z0-9]*', '\\1')}}"
  tasks:
    - name: stop manager leader nodes docker daemon
      shell: >
        sudo service docker stop

    - name: restart manager leader nodes docker daemon with labels
      shell: >
        nohup sudo dockerd
        -H unix:///var/run/docker.sock
        -H tcp://{{ ec2_private_ip_address }}:2375
        --label name={{ ec2_tag_Name }}
        --label environment={{ ec2_tag_environment }}
        --label environment-size={{ ec2_tag_environment_size }}
        --label environment-type={{ ec2_tag_environment_type }}
        --label failure-zone={{ ec2_tag_failure_zone }}
        --label subnet-type={{ ec2_tag_subnet_type }}
        --label swarm-instance-type={{ ec2_tag_swarm_instance_type }}
        --label swarm-node-type={{ ec2_tag_swarm_node_type }} &

    - name: initialize swarm cluster
      shell: >
        docker swarm init
        --advertise-addr={{ swarm_iface | default('eth0') }}:2377
      when: "'swarm_manager_operational' not in groups"
      register: bootstrap_first_node

    - name: add labels to docker manager leader swarm node
      shell: >
        docker node update
        --label-add name={{ ec2_tag_Name }}
        --label-add environment={{ ec2_tag_environment }}
        --label-add environment-size={{ ec2_tag_environment_size }}
        --label-add environment-type={{ ec2_tag_environment_type }}
        --label-add failure-zone={{ ec2_tag_failure_zone }}
        --label-add subnet-type={{ ec2_tag_subnet_type }}
        --label-add swarm-instance-type={{ ec2_tag_swarm_instance_type }}
        --label-add swarm-node-type={{ ec2_tag_swarm_node_type }}
        '{{ swarm_node_host_name }}'

    - name: add initialized host to swarm_manager_operational group
      add_host:
        hostname: "{{ item }}"
        groups: swarm_manager_operational
      with_items: "{{ ansible_play_hosts | default(play_hosts) }}"
      when: bootstrap_first_node | changed

# retrieve the swarm tokens and populate a list of ips listening on
# the swarm port 2377
- hosts: swarm_manager_operational[0]
  become: true
  vars:
    iface: "{{ swarm_iface | default('eth0') }}"
  tasks:
    - name: retrieve swarm manager token
      shell: docker swarm join-token -q manager
      register: swarm_manager_token

    - name: retrieve swarm worker token
      shell: docker swarm join-token -q worker
      register: swarm_worker_token

    - name: populate list of manager ips
      add_host:
        hostname: "{{ hostvars[item]['ansible_' + iface]['ipv4']['address'] }}"
        groups: swarm_manager_ips
      with_items: "{{ ansible_play_hosts | default(play_hosts) }}"

# join the manager hosts not yet initialized to the swarm cluster
- hosts: swarm_manager_bootstrap:!swarm_manager_operational
  become: true
  vars:
    token: "{{ hostvars[groups['swarm_manager_operational'][0]]['swarm_manager_token']['stdout'] }}"
    swarm_node_host_name: "{{ ec2_private_dns_name | regex_replace('(ip-[0-9]*-[0-9]*-[0-9]*-[0-9]*)\\.[a-zA-Z0-9]*\\.[a-zA-Z0-9]*', '\\1')}}"
  tasks:
    - name: stop manager follower nodes docker daemon
      shell: >
        sudo service docker stop

    - name: restart manager follower nodes docker daemon with labels
      shell: >
        nohup sudo dockerd
        -H unix:///var/run/docker.sock
        -H tcp://{{ ec2_private_ip_address }}:2375
        --label name={{ ec2_tag_Name }}
        --label environment={{ ec2_tag_environment }}
        --label environment-size={{ ec2_tag_environment_size }}
        --label environment-type={{ ec2_tag_environment_type }}
        --label failure-zone={{ ec2_tag_failure_zone }}
        --label subnet-type={{ ec2_tag_subnet_type }}
        --label swarm-instance-type={{ ec2_tag_swarm_instance_type }}
        --label swarm-node-type={{ ec2_tag_swarm_node_type }} &

    - name: join manager nodes to cluster
      shell: >
        docker swarm join
        --advertise-addr={{ swarm_iface | default('eth0') }}:2377
        --token={{ token }}
        {{ groups['swarm_manager_ips'][0] }}:2377

    - name: add labels to docker manager follower swarm node
      shell: >
        docker node update
        --label-add name={{ ec2_tag_Name }}
        --label-add environment={{ ec2_tag_environment }}
        --label-add environment-size={{ ec2_tag_environment_size }}
        --label-add environment-type={{ ec2_tag_environment_type }}
        --label-add failure-zone={{ ec2_tag_failure_zone }}
        --label-add subnet-type={{ ec2_tag_subnet_type }}
        --label-add swarm-instance-type={{ ec2_tag_swarm_instance_type }}
        --label-add swarm-node-type={{ ec2_tag_swarm_node_type }}
        '{{ swarm_node_host_name }}'



# join the worker hosts not yet initialized to the swarm cluster
- hosts: swarm_worker_bootstrap
  become: true
  vars:
    token: "{{ hostvars[groups['swarm_manager_operational'][0]]['swarm_worker_token']['stdout'] }}"
    swarm_node_host_name: "{{ ec2_private_dns_name | regex_replace('(ip-[0-9]*-[0-9]*-[0-9]*-[0-9]*)\\.[a-zA-Z0-9]*\\.[a-zA-Z0-9]*', '\\1')}}"
  tasks:
    - name: stop worker nodes docker daemon
      shell: >
        sudo service docker stop

    - name: restart worker nodes docker daemon with labels
      shell: >
        nohup sudo dockerd
        -H unix:///var/run/docker.sock
        -H tcp://{{ ec2_private_ip_address }}:2375
        --label name={{ ec2_tag_Name }}
        --label environment={{ ec2_tag_environment }}
        --label environment-size={{ ec2_tag_environment_size }}
        --label environment-type={{ ec2_tag_environment_type }}
        --label failure-zone={{ ec2_tag_failure_zone }}
        --label subnet-type={{ ec2_tag_subnet_type }}
        --label swarm-instance-type={{ ec2_tag_swarm_instance_type }}
        --label swarm-node-type={{ ec2_tag_swarm_node_type }} &

    - name: join worker nodes to cluster
      shell: >
        docker swarm join
        --advertise-addr={{ swarm_iface | default('eth0') }}:2377
        --token={{ token }}
        {{ groups['swarm_manager_ips'][0] }}:2377

    - name: add labels to docker worker swarm node
      shell: >
        docker -H {{ groups['swarm_manager_ips'][0] }}:2375 node update
        --label-add name={{ ec2_tag_Name }}
        --label-add environment={{ ec2_tag_environment }}
        --label-add environment-size={{ ec2_tag_environment_size }}
        --label-add environment-type={{ ec2_tag_environment_type }}
        --label-add failure-zone={{ ec2_tag_failure_zone }}
        --label-add subnet-type={{ ec2_tag_subnet_type }}
        --label-add swarm-instance-type={{ ec2_tag_swarm_instance_type }}
        --label-add swarm-node-type={{ ec2_tag_swarm_node_type }}
        '{{ swarm_node_host_name }}'
