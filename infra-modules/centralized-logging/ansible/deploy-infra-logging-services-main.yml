---
# determine the status of each manager node and break them
# into two groups:
#   - swarm_manager_operational (swarm is running and active)
#   - swarm_manager_bootstrap (host needs to be joined to the cluster)
- hosts: tag_jra_environment_{{ env }}:&tag_jra_swarm_instance_type_swarm_manager
  become: true
  tasks:
    - name: determine swarm status
      shell: >
        docker info | egrep '^Swarm: ' | cut -d ' ' -f2
      register: swarm_status

    - name: create swarm_manager_operational group
      add_host:
        hostname: "{{ item }}"
        groups: swarm_manager_operational
      with_items: "{{ ansible_play_hosts | default(play_hosts) }}"
      when: "'active' in hostvars[item].swarm_status.stdout_lines"
      run_once: true

    - name: create swarm_manager_bootstrap group
      add_host:
        hostname: "{{ item }}"
        groups: swarm_manager_bootstrap
      with_items: "{{ ansible_play_hosts | default(play_hosts) }}"
      when: "'active' not in hostvars[item].swarm_status.stdout_lines"
      run_once: true

# Make sure all data mount volues and script directories are created on host machines
- hosts: tag_jra_environment_{{ env }}:&tag_jra_swarm_node_type_infra_logging
  become: true
  tasks:
    - name: create the elasticsearch mount directory if it doesn't already exist
      shell: >
        sudo mkdir -p /usr/local/jra/docker-data-volumes/jra-infra/logging-elasticsearch/data
      ignore_errors: yes

    - name: create the elasticsearch mount directory if it doesn't already exist
      shell: >
        sudo mkdir -p /usr/local/jra/docker-data-volumes/jra-infra/logging-fluentd/data
      ignore_errors: yes

    - name: make sure the processes running inside containers have access to the directories
      shell: >
        sudo chmod -R 777 /usr/local/jra
      ignore_errors: yes

    - name: update the mmap limit because elasticsearch needs it
      shell: >
        sudo sysctl -w vm.max_map_count=262144 &&
        sudo bash -c 'sudo echo "vm.max_map_count=262144" >> /etc/sysctl.conf'
      ignore_errors: yes


# Deploy the central logging docker swarm stack
- hosts: swarm_manager_operational[0]
  become: true
  tasks:
    - name: remove jarch-infra-logging stack if it exists (ignore failure if it does not exist)
      shell: >
        docker stack rm jarch-infra-logging
      ignore_errors: yes

    - name: create the elasticsearch mount directory if it doesn't already exist
      shell: >
        sudo mkdir -p /usr/local/jra/scripts/compose/jarch-infra-logging-stack
      ignore_errors: yes

    - name: copy the stack file
      copy:
        src: "{{ stack_file_dir }}/"
        dest: /usr/local/jra/scripts/compose/jarch-infra-logging-stack/

    - name: deploy central logging stack
      shell: >
        ENV_DOMAIN_PREFIX={{ env_domain_prefix }} docker stack deploy jarch-infra-logging -c {{ stack_file_name }}
      args:
        chdir: /usr/local/jra/scripts/compose/jarch-infra-logging-stack/
